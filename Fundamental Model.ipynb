{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-20T14:02:18.395024Z",
     "start_time": "2024-11-20T14:02:18.388296Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 225
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T14:02:18.626204Z",
     "start_time": "2024-11-20T14:02:18.410699Z"
    }
   },
   "cell_type": "code",
   "source": "data = pd.read_parquet('/Users/vittoriomanfriani/Desktop/bonds_us.pq')",
   "id": "e61ad66fab5fb242",
   "outputs": [],
   "execution_count": 226
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T14:02:18.678945Z",
     "start_time": "2024-11-20T14:02:18.674956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = data[:50000]\n",
    "data.head()"
   ],
   "id": "ac3b8596af608918",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                              price  yield  dv01  coupon   maturity\n",
       "timestamp  id                                                      \n",
       "2000-01-03 US912810BU17  100.812500  5.895   NaN   8.250 2005-05-15\n",
       "           US912810BX55  101.625000  6.781   NaN   7.625 2007-02-15\n",
       "           US912810BZ04  102.734375  6.803   NaN   7.875 2007-11-15\n",
       "           US912810CC00  104.968750  6.797   NaN   8.375 2008-08-15\n",
       "           US912810CE65  106.453125  6.817   NaN   8.750 2008-11-15"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>yield</th>\n",
       "      <th>dv01</th>\n",
       "      <th>coupon</th>\n",
       "      <th>maturity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2000-01-03</th>\n",
       "      <th>US912810BU17</th>\n",
       "      <td>100.812500</td>\n",
       "      <td>5.895</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.250</td>\n",
       "      <td>2005-05-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US912810BX55</th>\n",
       "      <td>101.625000</td>\n",
       "      <td>6.781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.625</td>\n",
       "      <td>2007-02-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US912810BZ04</th>\n",
       "      <td>102.734375</td>\n",
       "      <td>6.803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.875</td>\n",
       "      <td>2007-11-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US912810CC00</th>\n",
       "      <td>104.968750</td>\n",
       "      <td>6.797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.375</td>\n",
       "      <td>2008-08-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US912810CE65</th>\n",
       "      <td>106.453125</td>\n",
       "      <td>6.817</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.750</td>\n",
       "      <td>2008-11-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 227
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T14:02:18.764478Z",
     "start_time": "2024-11-20T14:02:18.732675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert 'maturity' to datetime\n",
    "data['maturity'] = pd.to_datetime(data['maturity'], errors='coerce')\n",
    "\n",
    "# Drop rows where the 'maturity' is NaT (missing)\n",
    "data = data.dropna(subset=['maturity'])\n",
    "\n",
    "# Compute time to maturity\n",
    "data.reset_index(inplace=True)\n",
    "data['time to maturity'] = (data['maturity'] - data['timestamp']) / pd.Timedelta(days=365.25)\n",
    "\n",
    "# Get time to maturities dataset\n",
    "maturities = data.pivot(index='timestamp', columns='id', values='time to maturity')\n",
    "maturities.head()\n",
    "\n",
    "# Get yield dataset\n",
    "yields = data.pivot(index='timestamp', columns='id', values='yield')"
   ],
   "id": "42bb31aff9a06f7e",
   "outputs": [],
   "execution_count": 228
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T14:02:18.874563Z",
     "start_time": "2024-11-20T14:02:18.785990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Before proceeding we interpolate nans only if there is one consecutive\n",
    "\n",
    "# Function to check single NaN in each column\n",
    "def is_single_nan(series):\n",
    "    mask = series.isna()\n",
    "    # Single NaN is identified as a NaN surrounded by non-NaNs\n",
    "    return mask & ~mask.shift(1, fill_value=False) & ~mask.shift(-1, fill_value=False)\n",
    "\n",
    "# apply the function both to maturities and yields dataset\n",
    "\n",
    "# Mask for single NaNs\n",
    "single_nan_mask_maturities = maturities.apply(is_single_nan)\n",
    "single_nan_mask_yields = yields.apply(is_single_nan)\n",
    "\n",
    "maturities = maturities.where(~single_nan_mask_maturities, maturities.interpolate(method='linear', limit=1, axis=0))\n",
    "yields = yields.where(~single_nan_mask_yields, yields.interpolate(method='linear', limit=1, axis=0))"
   ],
   "id": "62558e4800db04ad",
   "outputs": [],
   "execution_count": 229
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T14:02:18.879146Z",
     "start_time": "2024-11-20T14:02:18.877200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Apply Nelson-Siegel Model\n",
    "def nelson_siegel(params, maturities, lambd):\n",
    "    beta0, beta1, beta2 = params\n",
    "    t = maturities\n",
    "    alpha_1 = (1 - np.exp(-t/lambd))/(t/lambd)\n",
    "    alpha_2 = (1 - np.exp(-t/lambd))/(t/lambd) - np.exp(-t/lambd)\n",
    "    return beta0 + beta1 * alpha_1 + beta2 * alpha_2"
   ],
   "id": "96d8560b652a9e17",
   "outputs": [],
   "execution_count": 230
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T14:02:18.918148Z",
     "start_time": "2024-11-20T14:02:18.916419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Error function to minimize to find optimal params\n",
    "def error_function(params, maturities, data, lambd):\n",
    "    data_hat = nelson_siegel(params, maturities, lambd)\n",
    "    return np.sum((data - data_hat) ** 2)"
   ],
   "id": "1da04d021484daf1",
   "outputs": [],
   "execution_count": 231
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T14:04:52.144396Z",
     "start_time": "2024-11-20T14:04:52.122299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Apply Nelson-Siegel Model to the dataset\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def apply_nelson_siegel(yields, maturities, lambdas = list(np.linspace(0.027, 1, 10))):\n",
    "\n",
    "    # Store results in a DataFrame\n",
    "    fitted_results = []\n",
    "    test_metrics = []\n",
    "    \n",
    "    initial_params = [0.03, -0.01, 0.01] \n",
    "    lambdas.append(1.37)\n",
    "    lambdas.append(3)\n",
    "\n",
    "    for i in range(yields.shape[0]):\n",
    "        date = yields.index[i]\n",
    "        current_yields = yields.iloc[i].dropna()\n",
    "        current_maturities = maturities.iloc[i].dropna()\n",
    "        \n",
    "        # Align indices of current_yields and current_maturities\n",
    "        valid_indices = current_yields.index.intersection(current_maturities.index)\n",
    "        current_yields = current_yields.loc[valid_indices]\n",
    "        current_maturities = current_maturities.loc[valid_indices]\n",
    "        \n",
    "        # Split data into train and test sets (80% train, 20% test)\n",
    "        train_maturities, test_maturities, train_yields, test_yields = train_test_split(\n",
    "            current_maturities, current_yields, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        best_loss = float(\"inf\")\n",
    "        best_params = None\n",
    "        best_lambda = None\n",
    "\n",
    "        # Grid search over lambda\n",
    "        for lambd in lambdas:\n",
    "            result = minimize(\n",
    "                error_function,\n",
    "                initial_params,\n",
    "                args=(train_maturities, train_yields, lambd),  \n",
    "                method=\"L-BFGS-B\",\n",
    "                options={'maxiter': 1000}, \n",
    "            )\n",
    "\n",
    "            # Update best parameters and lambda if this result is better\n",
    "            if result.fun < best_loss:\n",
    "                best_loss = result.fun\n",
    "                best_params = result.x\n",
    "                best_lambda = lambd\n",
    "        \n",
    "        # Compute predictions on the test set\n",
    "        test_predictions = nelson_siegel(best_params, test_maturities, best_lambda)\n",
    "        \n",
    "        # Compute R^2\n",
    "        ss_res = np.sum((test_yields - test_predictions) ** 2)  \n",
    "        ss_tot = np.sum((test_yields - np.mean(test_yields)) ** 2) \n",
    "        r_squared = 1 - (ss_res / ss_tot)\n",
    "        \n",
    "        # Compute Mean Squared Error\n",
    "        mse = mean_squared_error(test_yields, test_predictions)\n",
    "\n",
    "        # Store results for the current date\n",
    "        fitted_results.append({\n",
    "            \"Date\": date,\n",
    "            \"Beta0 (Level)\": best_params[0],\n",
    "            \"Beta1 (Slope)\": best_params[1],\n",
    "            \"Beta2 (Curvature)\": best_params[2],\n",
    "            \"Lambda\": best_lambda, \n",
    "        })\n",
    "        \n",
    "        test_metrics.append({\n",
    "            \"Date\": date,\n",
    "            \"R^2\": r_squared,\n",
    "            \"MSE\": mse,\n",
    "        })\n",
    "\n",
    "    # Convert results to a DataFrame\n",
    "    fitted_results_df = pd.DataFrame(fitted_results)\n",
    "    test_metrics_df = pd.DataFrame(test_metrics)\n",
    "\n",
    "    return fitted_results_df, test_metrics_df"
   ],
   "id": "6af7621b9f3020e1",
   "outputs": [],
   "execution_count": 235
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T14:06:09.533782Z",
     "start_time": "2024-11-20T14:04:54.156412Z"
    }
   },
   "cell_type": "code",
   "source": "params, metrics = apply_nelson_siegel(yields, maturities)",
   "id": "234e3a59e69b85dd",
   "outputs": [],
   "execution_count": 236
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T14:06:56.632741Z",
     "start_time": "2024-11-20T14:06:56.620199Z"
    }
   },
   "cell_type": "code",
   "source": "metrics.mean()",
   "id": "77d4d59b3a5ea3cf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date    2000-07-28 21:15:42.281879168\n",
       "R^2                          0.576896\n",
       "MSE                          0.122532\n",
       "dtype: object"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 238
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T14:11:17.441193Z",
     "start_time": "2024-11-20T14:11:17.436428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Same Function but using Ridge Approach\n",
    "\n",
    "# We define ridge error function as\n",
    "def ridge_error_function(params, maturities, data, lambd, alpha=0.1):\n",
    "    data_hat = nelson_siegel(params, maturities, lambd)\n",
    "    error = np.sum((data - data_hat) ** 2) \n",
    "    regularization = alpha * (params[0]**2 + params[1]**2 + params[2]**2) \n",
    "    return error + regularization\n",
    "\n",
    "# Apply Nelson-Siegel Model to the dataset\n",
    "def apply_nelson_siegel_ridge(yields, maturities, lambdas = list(np.linspace(0.027, 1, 10)), alpha=0.1):\n",
    "    fitted_results = []\n",
    "    test_metrics = []\n",
    "    initial_params = [0.03, -0.01, 0.01] \n",
    "    lambdas.append(1.37)\n",
    "    lambdas.append(3)\n",
    "\n",
    "    for i in range(yields.shape[0]):\n",
    "        date = yields.index[i]\n",
    "        current_yields = yields.iloc[i].dropna()\n",
    "        current_maturities = maturities.iloc[i].dropna()\n",
    "        \n",
    "        # Align indices of current_yields and current_maturities\n",
    "        valid_indices = current_yields.index.intersection(current_maturities.index)\n",
    "        current_yields = current_yields.loc[valid_indices]\n",
    "        current_maturities = current_maturities.loc[valid_indices]\n",
    "        \n",
    "        # Split data into train and test sets (80% train, 20% test)\n",
    "        train_maturities, test_maturities, train_yields, test_yields = train_test_split(\n",
    "            current_maturities, current_yields, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        best_loss = float(\"inf\")\n",
    "        best_params = None\n",
    "        best_lambda = None\n",
    "\n",
    "        # Grid Search over lambdas\n",
    "        for lambd in lambdas:\n",
    "            result = minimize(\n",
    "                ridge_error_function,\n",
    "                initial_params,\n",
    "                args=(train_maturities, train_yields, lambd, alpha),\n",
    "                method=\"L-BFGS-B\",\n",
    "                options={'maxiter': 1000}  \n",
    "            )\n",
    "\n",
    "            if result.fun < best_loss:\n",
    "                best_loss = result.fun\n",
    "                best_params = result.x\n",
    "                best_lambda = lambd\n",
    "                \n",
    "        # Compute predictions on the test set\n",
    "        test_predictions = nelson_siegel(best_params, test_maturities, best_lambda)\n",
    "        \n",
    "        # Compute R^2\n",
    "        ss_res = np.sum((test_yields - test_predictions) ** 2)  \n",
    "        ss_tot = np.sum((test_yields - np.mean(test_yields)) ** 2) \n",
    "        r_squared = 1 - (ss_res / ss_tot)\n",
    "        \n",
    "        # Compute Mean Squared Error\n",
    "        mse = mean_squared_error(test_yields, test_predictions)\n",
    "\n",
    "        # Store results\n",
    "        fitted_results.append({\n",
    "            \"Date\": date,\n",
    "            \"Beta0 (Level)\": best_params[0],\n",
    "            \"Beta1 (Slope)\": best_params[1],\n",
    "            \"Beta2 (Curvature)\": best_params[2],\n",
    "            \"Lambda 1\": best_lambda,\n",
    "        })\n",
    "\n",
    "        test_metrics.append({\n",
    "                    \"Date\": date,\n",
    "                    \"R^2\": r_squared,\n",
    "                    \"MSE\": mse,\n",
    "                })\n",
    "        \n",
    "        # Convert results to a DataFrame\n",
    "        fitted_results_df = pd.DataFrame(fitted_results)\n",
    "        test_metrics_df = pd.DataFrame(test_metrics)\n",
    "\n",
    "    return fitted_results_df, test_metrics_df"
   ],
   "id": "fad40d32dc2331d4",
   "outputs": [],
   "execution_count": 249
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T14:13:57.793709Z",
     "start_time": "2024-11-20T14:12:35.173573Z"
    }
   },
   "cell_type": "code",
   "source": "params_ridge, metrics_ridge = apply_nelson_siegel_ridge(yields, maturities)",
   "id": "1b282321938440af",
   "outputs": [],
   "execution_count": 251
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T14:14:09.406500Z",
     "start_time": "2024-11-20T14:14:09.392825Z"
    }
   },
   "cell_type": "code",
   "source": "metrics_ridge.mean()",
   "id": "3ba5f35a620a3dd0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date    2000-07-28 21:15:42.281879168\n",
       "R^2                          0.557819\n",
       "MSE                          0.113212\n",
       "dtype: object"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 252
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T14:23:51.280683Z",
     "start_time": "2024-11-20T14:23:51.235232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# clean the dataset of factors\n",
    "factors_df = pd.DataFrame(index = params.Date)\n",
    "factors_df['Beta0 (Level)'] = np.array(params['Beta0 (Level)'])\n",
    "factors_df['Beta1 (Slope)'] = np.array(params['Beta1 (Slope)'])\n",
    "factors_df['Beta2 (Curvature)'] = np.array(params['Beta2 (Curvature)'])"
   ],
   "id": "9520b78ca256d94d",
   "outputs": [],
   "execution_count": 254
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T14:23:52.358215Z",
     "start_time": "2024-11-20T14:23:52.353216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# clean the dataset of factors from ridge model\n",
    "factors_df_ridge = pd.DataFrame(index = params.Date)\n",
    "factors_df_ridge['Beta0 (Level)'] = np.array(params_ridge['Beta0 (Level)'])\n",
    "factors_df_ridge['Beta1 (Slope)'] = np.array(params_ridge['Beta1 (Slope)'])\n",
    "factors_df_ridge['Beta2 (Curvature)'] = np.array(params_ridge['Beta2 (Curvature)']) "
   ],
   "id": "c106211c2da92ec",
   "outputs": [],
   "execution_count": 255
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T14:23:54.072071Z",
     "start_time": "2024-11-20T14:23:53.969704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get dataset of returns\n",
    "\n",
    "# First we get a dataset of prices\n",
    "prices = data.pivot(index='timestamp', columns='id', values='price')\n",
    "\n",
    "# Then we get a dataset of coupons\n",
    "coupons = data.pivot(index='timestamp', columns='id', values='coupon')\n",
    "\n",
    "# Before proceeding we interpolate nans only if there is one consecutive\n",
    "\n",
    "# apply the function both to prices and coupons dataset\n",
    "\n",
    "# Mask for single NaNs\n",
    "single_nan_mask_prices = coupons.apply(is_single_nan)\n",
    "single_nan_mask_coupons = prices.apply(is_single_nan)\n",
    "\n",
    "prices = prices.where(~single_nan_mask_prices, prices.interpolate(method='linear', limit=1, axis=0))\n",
    "coupons = coupons.where(~single_nan_mask_coupons, coupons.interpolate(method='linear', limit=1, axis=0))\n",
    "\n",
    "# Function to compute returns\n",
    "def compute_returns(prices, coupons):\n",
    "    # Get Daily Coupons\n",
    "    daily_coupons = coupons/365\n",
    "    \n",
    "    # compute returns with formula (R_(t, t+1) = P_(t+1) + c  - P_(t) / P(t))\n",
    "    returns = (prices + daily_coupons - prices.shift(1))/prices.shift(1)\n",
    "    \n",
    "    return returns \n",
    "\n",
    "returns = compute_returns(prices,coupons)\n"
   ],
   "id": "93bd848a7f62d754",
   "outputs": [],
   "execution_count": 256
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T14:23:55.593965Z",
     "start_time": "2024-11-20T14:23:55.589388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Align the factors dataset to the on of returns\n",
    "factors_df = factors_df.iloc[1:]\n",
    "factors_df_ridge = factors_df_ridge.iloc[1:]\n",
    "returns = returns.iloc[1:]"
   ],
   "id": "b83c1ff4f1dc8257",
   "outputs": [],
   "execution_count": 257
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T14:23:57.358795Z",
     "start_time": "2024-11-20T14:23:57.350818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "def rolling_regression(data, factors_df, window_size=252):\n",
    "    # Initialize data structures to store loadings\n",
    "    loading_datasets = {factor: pd.DataFrame(index=data.index[window_size:], columns=data.columns) \n",
    "                        for factor in ['const'] + list(factors_df.columns)}\n",
    "    #Initialize dataset to store % variance explained\n",
    "    variance_explained = pd.DataFrame(index=data.index[window_size:], columns=data.columns)\n",
    "\n",
    "    # Iterate over each asset (column in `data`)\n",
    "    for col in data.columns:\n",
    "        y = data[col]\n",
    "        \n",
    "        # Perform rolling window regression\n",
    "        for i in range(window_size, len(data)):\n",
    "            \n",
    "            # Handle Nans\n",
    "            if pd.isna(data.loc[data.index[i], col]):\n",
    "                for factor in ['const'] + list(factors_df.columns):\n",
    "                    loading_datasets[factor].loc[data.index[i], col] = np.nan\n",
    "                continue\n",
    "                    \n",
    "            # Select rolling window data\n",
    "            y_window = y.iloc[i - window_size:i].dropna()\n",
    "            X_window = factors_df.iloc[i - window_size:i]\n",
    "            X_window = sm.add_constant(X_window)\n",
    "\n",
    "            # Handle Nans if window length is not enough to perform the regression\n",
    "            if y_window.shape[0] < window_size * 0.5:\n",
    "                for factor in ['const'] + list(factors_df.columns):\n",
    "                    loading_datasets[factor].loc[data.index[i], col] = np.nan\n",
    "                continue\n",
    "                    \n",
    "            X_window = X_window.loc[y_window.index]\n",
    "                    \n",
    "            # Perform regression\n",
    "            model = sm.OLS(y_window, X_window).fit()\n",
    "            \n",
    "            \n",
    "            # Compute variance explained (R^2 as a percentage)\n",
    "            y_pred = model.fittedvalues\n",
    "            ss_res = np.sum((y_window - y_pred) ** 2)  # Residual Sum of Squares\n",
    "            ss_tot = np.sum((y_window - np.mean(y_window)) ** 2)  # Total Sum of Squares\n",
    "            r_squared = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0\n",
    "            variance_explained.loc[data.index[i], col] = r_squared * 100\n",
    "            \n",
    "            # Store coefficients for each factor\n",
    "            for factor, loading in model.params.items():\n",
    "                loading_datasets[factor].loc[data.index[i], col] = loading\n",
    "\n",
    "    # Convert each DataFrame to numeric (to handle NaNs properly)\n",
    "    for factor in loading_datasets:\n",
    "        loading_datasets[factor] = loading_datasets[factor].astype(float)\n",
    "\n",
    "    return loading_datasets, variance_explained"
   ],
   "id": "24dbc3593302dcde",
   "outputs": [],
   "execution_count": 258
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T14:24:09.884712Z",
     "start_time": "2024-11-20T14:24:02.545770Z"
    }
   },
   "cell_type": "code",
   "source": "loading_datasets, variance_explained = rolling_regression(returns, factors_df)",
   "id": "1cb5de6a09fb8198",
   "outputs": [],
   "execution_count": 259
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T14:25:23.070042Z",
     "start_time": "2024-11-20T14:25:23.049454Z"
    }
   },
   "cell_type": "code",
   "source": "variance_explained.mean()",
   "id": "ee31e09d6678fd24",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "US912810BU17         NaN\n",
       "US912810BX55    8.657514\n",
       "US912810BZ04    8.678317\n",
       "US912810CC00    8.639706\n",
       "US912810CE65    8.602406\n",
       "                  ...   \n",
       "US912827Z627    3.537474\n",
       "US912827Z882    5.181493\n",
       "US912827ZE51         NaN\n",
       "US912827ZN50         NaN\n",
       "US912827ZX33    2.391313\n",
       "Length: 199, dtype: object"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 265
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T14:24:32.955702Z",
     "start_time": "2024-11-20T14:24:25.794229Z"
    }
   },
   "cell_type": "code",
   "source": "loading_datasets_ridge, variance_explained_ridge = rolling_regression(returns, factors_df_ridge)",
   "id": "ba4def48879d3a95",
   "outputs": [],
   "execution_count": 261
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T14:25:15.632691Z",
     "start_time": "2024-11-20T14:25:15.622574Z"
    }
   },
   "cell_type": "code",
   "source": "variance_explained_ridge.mean()",
   "id": "1b4329a5a08a3f1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "US912810BU17         NaN\n",
       "US912810BX55    9.549163\n",
       "US912810BZ04    9.564854\n",
       "US912810CC00    9.537271\n",
       "US912810CE65    9.513438\n",
       "                  ...   \n",
       "US912827Z627    2.410256\n",
       "US912827Z882    3.368479\n",
       "US912827ZE51         NaN\n",
       "US912827ZN50         NaN\n",
       "US912827ZX33     1.80793\n",
       "Length: 199, dtype: object"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 264
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T14:25:35.794133Z",
     "start_time": "2024-11-20T14:25:35.789189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def factor_and_idio_returns(returns, loading_datasets):\n",
    "    \n",
    "    # get columns names\n",
    "    names = list(loading_datasets.keys())[1:]\n",
    "    \n",
    "    factor_returns = pd.DataFrame(index=loading_datasets[names[0]].index, columns=loading_datasets[names[0]].columns)\n",
    "    idio_returns = pd.DataFrame(index=loading_datasets[names[0]].index, columns=loading_datasets[names[0]].columns)\n",
    "    factor_returns.fillna(0, inplace=True)\n",
    "    idio_returns.fillna(0, inplace=True)\n",
    "    \n",
    "    # align the returns dataset\n",
    "    returns = returns.loc[factor_returns.index]\n",
    "\n",
    "    for name in names:\n",
    "        factor_returns += loading_datasets[name] * returns\n",
    "    \n",
    "    idio_returns = returns - factor_returns\n",
    "    \n",
    "    return factor_returns, idio_returns"
   ],
   "id": "311e49bd75689f96",
   "outputs": [],
   "execution_count": 266
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T14:25:36.978947Z",
     "start_time": "2024-11-20T14:25:36.953843Z"
    }
   },
   "cell_type": "code",
   "source": "factor_returns, idio_returns = factor_and_idio_returns(returns, loading_datasets)",
   "id": "f54980af18a4f5dd",
   "outputs": [],
   "execution_count": 267
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T14:25:38.178421Z",
     "start_time": "2024-11-20T14:25:38.144677Z"
    }
   },
   "cell_type": "code",
   "source": "factor_returns_ridge, idio_returns_ridge = factor_and_idio_returns(returns, loading_datasets_ridge)",
   "id": "dee0777be4fb6048",
   "outputs": [],
   "execution_count": 268
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

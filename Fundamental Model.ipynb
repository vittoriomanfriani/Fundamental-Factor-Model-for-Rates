{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-20T18:54:53.136328Z",
     "start_time": "2024-11-20T18:54:53.132509Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 299
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T18:54:53.576406Z",
     "start_time": "2024-11-20T18:54:53.142697Z"
    }
   },
   "cell_type": "code",
   "source": "data = pd.read_parquet('/Users/vittoriomanfriani/Desktop/bonds_us.pq')",
   "id": "e61ad66fab5fb242",
   "outputs": [],
   "execution_count": 300
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T18:54:53.694864Z",
     "start_time": "2024-11-20T18:54:53.689085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = data[:50000]\n",
    "data.head()"
   ],
   "id": "ac3b8596af608918",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                              price  yield  dv01  coupon   maturity\n",
       "timestamp  id                                                      \n",
       "2000-01-03 US912810BU17  100.812500  5.895   NaN   8.250 2005-05-15\n",
       "           US912810BX55  101.625000  6.781   NaN   7.625 2007-02-15\n",
       "           US912810BZ04  102.734375  6.803   NaN   7.875 2007-11-15\n",
       "           US912810CC00  104.968750  6.797   NaN   8.375 2008-08-15\n",
       "           US912810CE65  106.453125  6.817   NaN   8.750 2008-11-15"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>yield</th>\n",
       "      <th>dv01</th>\n",
       "      <th>coupon</th>\n",
       "      <th>maturity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2000-01-03</th>\n",
       "      <th>US912810BU17</th>\n",
       "      <td>100.812500</td>\n",
       "      <td>5.895</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.250</td>\n",
       "      <td>2005-05-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US912810BX55</th>\n",
       "      <td>101.625000</td>\n",
       "      <td>6.781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.625</td>\n",
       "      <td>2007-02-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US912810BZ04</th>\n",
       "      <td>102.734375</td>\n",
       "      <td>6.803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.875</td>\n",
       "      <td>2007-11-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US912810CC00</th>\n",
       "      <td>104.968750</td>\n",
       "      <td>6.797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.375</td>\n",
       "      <td>2008-08-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US912810CE65</th>\n",
       "      <td>106.453125</td>\n",
       "      <td>6.817</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.750</td>\n",
       "      <td>2008-11-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 301
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T18:54:53.755175Z",
     "start_time": "2024-11-20T18:54:53.716544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert 'maturity' to datetime\n",
    "data['maturity'] = pd.to_datetime(data['maturity'], errors='coerce')\n",
    "\n",
    "# Drop rows where the 'maturity' is NaT (missing)\n",
    "data = data.dropna(subset=['maturity'])\n",
    "\n",
    "# Compute time to maturity\n",
    "data.reset_index(inplace=True)\n",
    "data['time to maturity'] = (data['maturity'] - data['timestamp']) / pd.Timedelta(days=365.25)\n",
    "\n",
    "# Get time to maturities dataset\n",
    "maturities = data.pivot(index='timestamp', columns='id', values='time to maturity')\n",
    "maturities.head()\n",
    "\n",
    "# Get yield dataset\n",
    "yields = data.pivot(index='timestamp', columns='id', values='yield')"
   ],
   "id": "42bb31aff9a06f7e",
   "outputs": [],
   "execution_count": 302
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T18:54:53.898198Z",
     "start_time": "2024-11-20T18:54:53.786375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Before proceeding we interpolate nans only if there is one consecutive\n",
    "\n",
    "# Function to check single NaN in each column\n",
    "def is_single_nan(series):\n",
    "    mask = series.isna()\n",
    "    # Single NaN is identified as a NaN surrounded by non-NaNs\n",
    "    return mask & ~mask.shift(1, fill_value=False) & ~mask.shift(-1, fill_value=False)\n",
    "\n",
    "# apply the function both to maturities and yields dataset\n",
    "\n",
    "# Mask for single NaNs\n",
    "single_nan_mask_maturities = maturities.apply(is_single_nan)\n",
    "single_nan_mask_yields = yields.apply(is_single_nan)\n",
    "\n",
    "maturities = maturities.where(~single_nan_mask_maturities, maturities.interpolate(method='linear', limit=1, axis=0))\n",
    "yields = yields.where(~single_nan_mask_yields, yields.interpolate(method='linear', limit=1, axis=0))"
   ],
   "id": "62558e4800db04ad",
   "outputs": [],
   "execution_count": 303
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T18:56:11.946945Z",
     "start_time": "2024-11-20T18:56:11.932110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Apply Nelson-Siegel Model\n",
    "def nelson_siegel(params, maturities, lambd):\n",
    "    beta0, beta1, beta2 = params\n",
    "    t = maturities\n",
    "    alpha_1 = (1 - np.exp(-t/lambd))/(t/lambd)\n",
    "    alpha_2 = (1 - np.exp(-t/lambd))/(t/lambd) - np.exp(-t/lambd)\n",
    "    return beta0 + beta1 * alpha_1 + beta2 * alpha_2"
   ],
   "id": "96d8560b652a9e17",
   "outputs": [],
   "execution_count": 313
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T18:54:53.979889Z",
     "start_time": "2024-11-20T18:54:53.975143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Error function to minimize to find optimal params\n",
    "def error_function(params, maturities, data, lambd):\n",
    "    data_hat = nelson_siegel(params, maturities, lambd)\n",
    "    return np.sum((data - data_hat) ** 2)\n",
    "\n",
    "# We define ridge error function as\n",
    "def ridge_error_function(params, maturities, data, lambd, alpha=0.1):\n",
    "    data_hat = nelson_siegel(params, maturities, lambd)\n",
    "    error = np.sum((data - data_hat) ** 2) \n",
    "    regularization = alpha * (params[0]**2 + params[1]**2 + params[2]**2) \n",
    "    return error + regularization"
   ],
   "id": "1da04d021484daf1",
   "outputs": [],
   "execution_count": 305
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T18:55:42.472603Z",
     "start_time": "2024-11-20T18:55:42.460534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Apply Nelson-Siegel Model to the dataset\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def apply_nelson_siegel(yields, maturities, lambdas = list(np.linspace(0.027, 1, 10)), ridge = False, alpha = 0.1):\n",
    "\n",
    "    # Store results in a DataFrame\n",
    "    fitted_results = []\n",
    "    test_metrics = []\n",
    "    \n",
    "    initial_params = [0.03, -0.01, 0.01] \n",
    "    \n",
    "    # Append arbitrary values to the list of possible lambdas \n",
    "    # (1.37 is the one that reflects best the curvature of \n",
    "    # the yield curve and 3 is the one that handles best multicollinearity)\n",
    "    lambdas.append(1.37)\n",
    "    lambdas.append(3)\n",
    "\n",
    "    for i in range(yields.shape[0]):\n",
    "        date = yields.index[i]\n",
    "        current_yields = yields.iloc[i].dropna()\n",
    "        current_maturities = maturities.iloc[i].dropna()\n",
    "        \n",
    "        # Align indices of current_yields and current_maturities\n",
    "        valid_indices = current_yields.index.intersection(current_maturities.index)\n",
    "        current_yields = current_yields.loc[valid_indices]\n",
    "        current_maturities = current_maturities.loc[valid_indices]\n",
    "        \n",
    "        # Split data into train and test sets (80% train, 20% test)\n",
    "        train_maturities, test_maturities, train_yields, test_yields = train_test_split(\n",
    "            current_maturities, current_yields, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Initialize variables to store best parameters\n",
    "        best_loss = float(\"inf\")\n",
    "        best_params = None\n",
    "        best_lambda = None\n",
    "\n",
    "        # Grid search over lambda\n",
    "        for lambd in lambdas:\n",
    "            \n",
    "            if ridge == False:\n",
    "                result = minimize(\n",
    "                    error_function,\n",
    "                    initial_params,\n",
    "                    args=(train_maturities, train_yields, lambd),  \n",
    "                    method=\"L-BFGS-B\",\n",
    "                    options={'maxiter': 1000}, \n",
    "                )\n",
    "            \n",
    "            if ridge == True:\n",
    "                # Grid Search over lambdas\n",
    "                result = minimize(\n",
    "                    ridge_error_function,\n",
    "                    initial_params,\n",
    "                    args=(train_maturities, train_yields, lambd, alpha),\n",
    "                    method=\"L-BFGS-B\",\n",
    "                    options={'maxiter': 1000}  \n",
    "                )\n",
    "            # Update best parameters and lambda if this result is better\n",
    "            if result.fun < best_loss:\n",
    "                best_loss = result.fun\n",
    "                best_params = result.x\n",
    "                best_lambda = lambd\n",
    "        \n",
    "        # Compute predictions on the test set\n",
    "        test_predictions = nelson_siegel(best_params, test_maturities, best_lambda)\n",
    "        \n",
    "        # Compute R^2\n",
    "        ss_res = np.sum((test_yields - test_predictions) ** 2)  \n",
    "        ss_tot = np.sum((test_yields - np.mean(test_yields)) ** 2) \n",
    "        r_squared = 1 - (ss_res / ss_tot)\n",
    "        \n",
    "        # Compute Mean Squared Error\n",
    "        mse = mean_squared_error(test_yields, test_predictions)\n",
    "\n",
    "        # Store results for the current date\n",
    "        fitted_results.append({\n",
    "            \"Date\": date,\n",
    "            \"Beta0 (Level)\": best_params[0],\n",
    "            \"Beta1 (Slope)\": best_params[1],\n",
    "            \"Beta2 (Curvature)\": best_params[2],\n",
    "            \"Lambda\": best_lambda, \n",
    "        })\n",
    "        \n",
    "        test_metrics.append({\n",
    "            \"Date\": date,\n",
    "            \"R^2\": r_squared,\n",
    "            \"MSE\": mse,\n",
    "        })\n",
    "\n",
    "    # Convert results to a DataFrame\n",
    "    fitted_results_df = pd.DataFrame(fitted_results)\n",
    "    test_metrics_df = pd.DataFrame(test_metrics)\n",
    "\n",
    "    return fitted_results_df, test_metrics_df"
   ],
   "id": "6af7621b9f3020e1",
   "outputs": [],
   "execution_count": 311
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T19:04:41.427654Z",
     "start_time": "2024-11-20T19:04:41.409109Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Optimization problems without grid search but treating lambda as another parameter to optimize\n",
    "\n",
    "# Updated Nelson-Siegel model\n",
    "def nelson_siegel_lambd(params, maturities):\n",
    "    beta0, beta1, beta2, lambd = params\n",
    "    \n",
    "    # set a min value for lambda to account for 0 division in optimization problems\n",
    "    lambd = max(lambd, 1e-6)\n",
    "    \n",
    "    t = maturities\n",
    "    \n",
    "    alpha_1 = (1 - np.exp(-t/lambd))/(t/lambd)\n",
    "    alpha_2 = (1 - np.exp(-t/lambd))/(t/lambd) - np.exp(-t/lambd)\n",
    "    return beta0 + beta1 * alpha_1 + beta2 * alpha_2\n",
    "\n",
    "# Error function to minimize to find optimal params\n",
    "def error_function_lambd(params, maturities, data):\n",
    "    data_hat = nelson_siegel_lambd(params, maturities)\n",
    "    return np.sum((data - data_hat) ** 2)\n",
    "\n",
    "# We define ridge error function as\n",
    "def ridge_error_function_lambd(params, maturities, data, alpha=0.1):\n",
    "    data_hat = nelson_siegel_lambd(params, maturities)\n",
    "    error = np.sum((data - data_hat) ** 2) \n",
    "    regularization = alpha * (params[0]**2 + params[1]**2 + params[2]**2) \n",
    "    return error + regularization\n",
    "\n",
    "\n",
    "# Fit the model to the data and get performance metrics\n",
    "def apply_nelson_siegel_lambd(yields, maturities, ridge = False, alpha = 0.1):\n",
    "\n",
    "    # Store results in a DataFrame\n",
    "    fitted_results = []\n",
    "    test_metrics = []\n",
    "    \n",
    "    initial_params = [0.01, 0.01, 0.01, 1] \n",
    "\n",
    "    for i in range(yields.shape[0]):\n",
    "        date = yields.index[i]\n",
    "        current_yields = yields.iloc[i].dropna()\n",
    "        current_maturities = maturities.iloc[i].dropna()\n",
    "        \n",
    "        # Align indices of current_yields and current_maturities\n",
    "        valid_indices = current_yields.index.intersection(current_maturities.index)\n",
    "        current_yields = current_yields.loc[valid_indices]\n",
    "        current_maturities = current_maturities.loc[valid_indices]\n",
    "        \n",
    "        # Split data into train and test sets (80% train, 20% test)\n",
    "        train_maturities, test_maturities, train_yields, test_yields = train_test_split(\n",
    "            current_maturities, current_yields, test_size=0.2, random_state=42\n",
    "        )\n",
    "        if ridge == False:\n",
    "            result = minimize(\n",
    "                    error_function_lambd,\n",
    "                    initial_params,\n",
    "                    args=(train_maturities, train_yields),  \n",
    "                    method=\"L-BFGS-B\",\n",
    "                    options={'maxiter': 1000}, \n",
    "                )\n",
    "            \n",
    "        if ridge == True:\n",
    "            result = minimize(\n",
    "                    ridge_error_function_lambd,\n",
    "                    initial_params,\n",
    "                    args=(train_maturities, train_yields, alpha),  \n",
    "                    method=\"L-BFGS-B\",\n",
    "                    options={'maxiter': 1000}, \n",
    "                )\n",
    "        \n",
    "        params = result.x\n",
    "        \n",
    "        # Compute predictions on the test set\n",
    "        test_predictions = nelson_siegel_lambd(params, test_maturities,)\n",
    "        \n",
    "        # Compute R^2\n",
    "        ss_res = np.sum((test_yields - test_predictions) ** 2)  \n",
    "        ss_tot = np.sum((test_yields - np.mean(test_yields)) ** 2) \n",
    "        r_squared = 1 - (ss_res / ss_tot)\n",
    "        \n",
    "        # Compute Mean Squared Error\n",
    "        mse = mean_squared_error(test_yields, test_predictions)\n",
    "\n",
    "        # Store results for the current date\n",
    "        fitted_results.append({\n",
    "            \"Date\": date,\n",
    "            \"Beta0 (Level)\": params[0],\n",
    "            \"Beta1 (Slope)\": params[1],\n",
    "            \"Beta2 (Curvature)\": params[2],\n",
    "            \"Lambda\": params[3], \n",
    "        })\n",
    "        \n",
    "        test_metrics.append({\n",
    "            \"Date\": date,\n",
    "            \"R^2\": r_squared,\n",
    "            \"MSE\": mse,\n",
    "        })\n",
    "\n",
    "    # Convert results to a DataFrame\n",
    "    fitted_results_df = pd.DataFrame(fitted_results)\n",
    "    test_metrics_df = pd.DataFrame(test_metrics)\n",
    "\n",
    "    return fitted_results_df, test_metrics_df"
   ],
   "id": "e07de6fd9b8cd4c",
   "outputs": [],
   "execution_count": 335
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T19:06:05.217017Z",
     "start_time": "2024-11-20T19:05:38.135431Z"
    }
   },
   "cell_type": "code",
   "source": "params, metrics = apply_nelson_siegel_lambd(yields, maturities, ridge=True)",
   "id": "234e3a59e69b85dd",
   "outputs": [],
   "execution_count": 338
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T19:06:06.727683Z",
     "start_time": "2024-11-20T19:06:06.723309Z"
    }
   },
   "cell_type": "code",
   "source": "metrics.mean()",
   "id": "77d4d59b3a5ea3cf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date    2000-07-28 21:15:42.281879168\n",
       "R^2                          0.562883\n",
       "MSE                          0.114856\n",
       "dtype: object"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 339
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T18:57:38.353238Z",
     "start_time": "2024-11-20T18:56:15.172108Z"
    }
   },
   "cell_type": "code",
   "source": "params_ridge, metrics_ridge = apply_nelson_siegel(yields, maturities, ridge = True)",
   "id": "1b282321938440af",
   "outputs": [],
   "execution_count": 314
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T18:57:51.783525Z",
     "start_time": "2024-11-20T18:57:51.769902Z"
    }
   },
   "cell_type": "code",
   "source": "metrics_ridge.mean()",
   "id": "3ba5f35a620a3dd0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date    2000-07-28 21:15:42.281879168\n",
       "R^2                          0.557819\n",
       "MSE                          0.113212\n",
       "dtype: object"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 315
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T18:58:11.028336Z",
     "start_time": "2024-11-20T18:58:11.006068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# clean the dataset of factors\n",
    "factors_df = pd.DataFrame(index = params.Date)\n",
    "factors_df['Beta0 (Level)'] = np.array(params['Beta0 (Level)'])\n",
    "factors_df['Beta1 (Slope)'] = np.array(params['Beta1 (Slope)'])\n",
    "factors_df['Beta2 (Curvature)'] = np.array(params['Beta2 (Curvature)'])"
   ],
   "id": "9520b78ca256d94d",
   "outputs": [],
   "execution_count": 317
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T18:58:12.365152Z",
     "start_time": "2024-11-20T18:58:12.357329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# clean the dataset of factors from ridge model\n",
    "factors_df_ridge = pd.DataFrame(index = params.Date)\n",
    "factors_df_ridge['Beta0 (Level)'] = np.array(params_ridge['Beta0 (Level)'])\n",
    "factors_df_ridge['Beta1 (Slope)'] = np.array(params_ridge['Beta1 (Slope)'])\n",
    "factors_df_ridge['Beta2 (Curvature)'] = np.array(params_ridge['Beta2 (Curvature)']) "
   ],
   "id": "c106211c2da92ec",
   "outputs": [],
   "execution_count": 318
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T18:58:14.341384Z",
     "start_time": "2024-11-20T18:58:14.238081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get dataset of returns\n",
    "\n",
    "# First we get a dataset of prices\n",
    "prices = data.pivot(index='timestamp', columns='id', values='price')\n",
    "\n",
    "# Then we get a dataset of coupons\n",
    "coupons = data.pivot(index='timestamp', columns='id', values='coupon')\n",
    "\n",
    "# Before proceeding we interpolate nans only if there is one consecutive\n",
    "\n",
    "# apply the function both to prices and coupons dataset\n",
    "\n",
    "# Mask for single NaNs\n",
    "single_nan_mask_prices = coupons.apply(is_single_nan)\n",
    "single_nan_mask_coupons = prices.apply(is_single_nan)\n",
    "\n",
    "prices = prices.where(~single_nan_mask_prices, prices.interpolate(method='linear', limit=1, axis=0))\n",
    "coupons = coupons.where(~single_nan_mask_coupons, coupons.interpolate(method='linear', limit=1, axis=0))\n",
    "\n",
    "# Function to compute returns\n",
    "def compute_returns(prices, coupons):\n",
    "    # Get Daily Coupons\n",
    "    daily_coupons = coupons/365\n",
    "    \n",
    "    # compute returns with formula (R_(t, t+1) = P_(t+1) + c  - P_(t) / P(t))\n",
    "    returns = (prices + daily_coupons - prices.shift(1))/prices.shift(1)\n",
    "    \n",
    "    return returns \n",
    "\n",
    "returns = compute_returns(prices,coupons)\n"
   ],
   "id": "93bd848a7f62d754",
   "outputs": [],
   "execution_count": 319
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T18:58:17.347094Z",
     "start_time": "2024-11-20T18:58:17.344471Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Align the factors dataset to the on of returns\n",
    "factors_df = factors_df.iloc[1:]\n",
    "factors_df_ridge = factors_df_ridge.iloc[1:]\n",
    "returns = returns.iloc[1:]"
   ],
   "id": "b83c1ff4f1dc8257",
   "outputs": [],
   "execution_count": 320
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T18:58:18.965742Z",
     "start_time": "2024-11-20T18:58:18.956933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "def rolling_regression(data, factors_df, window_size=252):\n",
    "    # Initialize data structures to store loadings\n",
    "    loading_datasets = {factor: pd.DataFrame(index=data.index[window_size:], columns=data.columns) \n",
    "                        for factor in ['const'] + list(factors_df.columns)}\n",
    "    #Initialize dataset to store % variance explained\n",
    "    variance_explained = pd.DataFrame(index=data.index[window_size:], columns=data.columns)\n",
    "\n",
    "    # Iterate over each asset (column in `data`)\n",
    "    for col in data.columns:\n",
    "        y = data[col]\n",
    "        \n",
    "        # Perform rolling window regression\n",
    "        for i in range(window_size, len(data)):\n",
    "            \n",
    "            # Handle Nans\n",
    "            if pd.isna(data.loc[data.index[i], col]):\n",
    "                for factor in ['const'] + list(factors_df.columns):\n",
    "                    loading_datasets[factor].loc[data.index[i], col] = np.nan\n",
    "                continue\n",
    "                    \n",
    "            # Select rolling window data\n",
    "            y_window = y.iloc[i - window_size:i].dropna()\n",
    "            X_window = factors_df.iloc[i - window_size:i]\n",
    "            X_window = sm.add_constant(X_window)\n",
    "\n",
    "            # Handle Nans if window length is not enough to perform the regression\n",
    "            if y_window.shape[0] < window_size * 0.5:\n",
    "                for factor in ['const'] + list(factors_df.columns):\n",
    "                    loading_datasets[factor].loc[data.index[i], col] = np.nan\n",
    "                continue\n",
    "                    \n",
    "            X_window = X_window.loc[y_window.index]\n",
    "                    \n",
    "            # Perform regression\n",
    "            model = sm.OLS(y_window, X_window).fit()\n",
    "            \n",
    "            \n",
    "            # Compute variance explained (R^2 as a percentage)\n",
    "            y_pred = model.fittedvalues\n",
    "            ss_res = np.sum((y_window - y_pred) ** 2)  # Residual Sum of Squares\n",
    "            ss_tot = np.sum((y_window - np.mean(y_window)) ** 2)  # Total Sum of Squares\n",
    "            r_squared = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0\n",
    "            variance_explained.loc[data.index[i], col] = r_squared * 100\n",
    "            \n",
    "            # Store coefficients for each factor\n",
    "            for factor, loading in model.params.items():\n",
    "                loading_datasets[factor].loc[data.index[i], col] = loading\n",
    "\n",
    "    return loading_datasets, variance_explained"
   ],
   "id": "24dbc3593302dcde",
   "outputs": [],
   "execution_count": 321
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T18:58:28.185308Z",
     "start_time": "2024-11-20T18:58:20.933386Z"
    }
   },
   "cell_type": "code",
   "source": "loading_datasets, variance_explained = rolling_regression(returns, factors_df)",
   "id": "1cb5de6a09fb8198",
   "outputs": [],
   "execution_count": 322
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T18:58:36.267714Z",
     "start_time": "2024-11-20T18:58:28.963318Z"
    }
   },
   "cell_type": "code",
   "source": "loading_datasets_ridge, variance_explained_ridge = rolling_regression(returns, factors_df_ridge)",
   "id": "ba4def48879d3a95",
   "outputs": [],
   "execution_count": 323
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T18:55:22.016030Z",
     "start_time": "2024-11-20T14:25:35.789189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def factor_and_idio_returns(returns, loading_datasets):\n",
    "    \n",
    "    # get columns names\n",
    "    names = list(loading_datasets.keys())[1:]\n",
    "    \n",
    "    factor_returns = pd.DataFrame(index=loading_datasets[names[0]].index, columns=loading_datasets[names[0]].columns)\n",
    "    idio_returns = pd.DataFrame(index=loading_datasets[names[0]].index, columns=loading_datasets[names[0]].columns)\n",
    "    factor_returns.fillna(0, inplace=True)\n",
    "    idio_returns.fillna(0, inplace=True)\n",
    "    \n",
    "    # align the returns dataset\n",
    "    returns = returns.loc[factor_returns.index]\n",
    "\n",
    "    for name in names:\n",
    "        factor_returns += loading_datasets[name] * returns\n",
    "    \n",
    "    idio_returns = returns - factor_returns\n",
    "    \n",
    "    return factor_returns, idio_returns"
   ],
   "id": "311e49bd75689f96",
   "outputs": [],
   "execution_count": 266
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T18:58:38.495693Z",
     "start_time": "2024-11-20T18:58:38.463875Z"
    }
   },
   "cell_type": "code",
   "source": "factor_returns, idio_returns = factor_and_idio_returns(returns, loading_datasets)",
   "id": "f54980af18a4f5dd",
   "outputs": [],
   "execution_count": 324
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T18:58:39.553382Z",
     "start_time": "2024-11-20T18:58:39.523084Z"
    }
   },
   "cell_type": "code",
   "source": "factor_returns_ridge, idio_returns_ridge = factor_and_idio_returns(returns, loading_datasets_ridge)",
   "id": "dee0777be4fb6048",
   "outputs": [],
   "execution_count": 325
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import logging"
   ],
   "id": "6e7676d2147c7c34"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "file_path = '/Users/vittoriomanfriani/Desktop/bond_data.xlsx'\n",
    "excel_data = pd.ExcelFile(file_path)\n",
    "df_raw = excel_data.parse('Sheet1', header=None)"
   ],
   "id": "495221c55665f9aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Extract the header row to identify ISINs and their column positions\n",
    "header = df_raw.iloc[0]\n",
    "header = [val.split()[0] if isinstance(val, str) and \"ISIN\" in val else val for val in header]"
   ],
   "id": "de35b21018cf7930"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Identify ISIN positions and their corrected names\n",
    "isin_positions = [(i, val) for i, val in enumerate(header) if isinstance(val, str) and re.match(r'^[A-Z0-9]{12}$', val)]"
   ],
   "id": "2ba743c574dd266d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Function to convert only numeric dates\n",
    "def convert_to_datetime(val):\n",
    "    if isinstance(val, (int, float)):  # Check if the value is numeric\n",
    "        return pd.to_datetime(val, origin='1899-12-30', unit='D')\n",
    "    elif isinstance(val, str):  # Check if the value is already a date string\n",
    "        return pd.to_datetime(val, errors='coerce')  # Convert if it's a valid date\n",
    "    return val  # Return as-is if it doesn't match above cases"
   ],
   "id": "183e2a6054b3f7fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Process each ISIN section and collect data\n",
    "data_frames = []\n",
    "for start_col, isin in isin_positions:\n",
    "    # Determine the end column for each ISIN section (4 columns per ISIN)\n",
    "    end_col = start_col + 4\n",
    "    temp_df = df_raw.iloc[2:, start_col:end_col]  # Skip the first two rows (headers)\n",
    "    temp_df.columns = [\"date\", \"mid_price\", \"yield\", \"mid_dv01\"]\n",
    "    temp_df[\"isin\"] = isin\n",
    "    \n",
    "    temp_df['date'] = temp_df['date'].apply(convert_to_datetime)\n",
    "    \n",
    "    temp_df.dropna(subset=['date'], inplace=True)  # Drop rows with any remaining invalid dates\n",
    "    \n",
    "    data_frames.append(temp_df)"
   ],
   "id": "fe0e88272cb639eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Concatenate all ISIN data into a single DataFrame\n",
    "final_df = pd.concat(data_frames, ignore_index=True)\n",
    "final_df.set_index([\"date\", \"isin\"], inplace=True)\n",
    "final_df = final_df.sort_index()"
   ],
   "id": "25861f4ec20ac640"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "final_df.to_csv('USBond_Dataset_Ordered.csv')",
   "id": "1da92e676ee4c7ab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ],
   "id": "ff9b876d0d1e6700"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "ccy = \"USD\"\n",
    "symbol_name = 'Bond'"
   ],
   "id": "33e4f49ce8ac0478"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# check that dates are daily\n",
    "dates = final_df.index.get_level_values(\"date\")\n",
    "assert isinstance(dates, pd.DatetimeIndex)\n",
    "\n",
    "dates_diff = dates.unique().to_series().diff()[1:] / np.timedelta64(1, 'h')\n",
    "\n",
    "if np.any(dates_diff < 20):\n",
    "     raise Exception('There are observations for which the timedelta is less than 1 day')\n",
    "\n",
    "avg_diff = np.mean(dates_diff)\n",
    "logger.info(f'Average timedelta for {ccy}_{symbol_name}: {avg_diff}')\n",
    "\n",
    "if not (avg_diff > 24 and avg_diff < 48):\n",
    "    raise Exception('For (more or less) daily observations, the timedelta between each observation'\n",
    "        'should be between 1 and 2 days, while the average timedelta in the data'\n",
    "        f'is {avg_diff} days.')"
   ],
   "id": "55cac6eda95b7298"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
